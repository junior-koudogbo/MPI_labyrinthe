\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{booktabs}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\geometry{margin=2.5cm}

% Configuration pour le code source
\lstset{
    language=C,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    frame=single,
    breaklines=true,
    showstringspaces=false,
    tabsize=2
}

\title{Parallélisation en mémoire distribuée :\\
       Génération de labyrinthe avec MPI}
\author{Junior Koudogbo}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Ce rapport présente la parallélisation de la génération de labyrinthe en utilisant MPI (Message Passing Interface) pour la programmation parallèle en mémoire distribuée. Je décris les modifications apportées au code séquentiel de référence, justifie mes choix d'implémentation, et présente une étude de performances incluant l'analyse de la scalabilité forte et faible de mon implémentation parallèle.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}

La génération de labyrinthes est un problème algorithmique classique qui peut nécessiter des calculs intensifs pour de grandes tailles. La parallélisation de ce type de problème permet d'exploiter efficacement les architectures parallèles modernes, notamment les clusters et les machines multi-cœurs. Ce projet s'intéresse à la parallélisation de la génération de labyrinthe en utilisant MPI, un standard de programmation parallèle en mémoire distribuée.

\section{Description du problème et de l'algorithme}

\subsection{Génération de labyrinthe}

L'algorithme de génération de labyrinthe utilisé dans ce projet est basé sur une approche itérative qui construit progressivement les murs du labyrinthe. Le principe général est le suivant :

\begin{enumerate}
\item Initialisation d'une grille avec des murs sur les bords et un espace vide à l'intérieur
\item Placement aléatoire d'îlots (murs) à l'intérieur du labyrinthe
\item Identification des cases constructibles (cases vides qui peuvent devenir des murs selon certaines règles)
\item Construction itérative : à chaque itération, sélection aléatoire d'une case constructible et transformation en mur, puis mise à jour des cases constructibles voisines
\end{enumerate}

Une case est dite \textbf{constructible} si elle est vide et si elle possède exactement un mur parmi ses 4 voisins directs (haut, bas, gauche, droite), avec les 4 voisins diagonaux vides. Cette règle garantit que le labyrinthe généré reste connexe et ne crée pas d'îlots isolés.

\subsection{Algorithme séquentiel}

L'algorithme séquentiel de référence (\texttt{gen\_lab.c}) procède de la manière suivante :

\begin{enumerate}
\item Initialisation de la grille de taille $N \times M$ : murs sur les bords ($i=0$, $i=N-1$, $j=0$, $j=M-1$), espace vide ailleurs
\item Placement de $nbilots$ îlots aléatoirement à l'intérieur du labyrinthe
\item Calcul initial des cases constructibles : parcours de toutes les cases intérieures et marquage des cases constructibles avec la valeur $-1$
\item Suppression aléatoire de quelques cases constructibles sur les bords pour éviter une génération trop régulière
\item Boucle principale :
\begin{itemize}
\item Sélection aléatoire d'une case constructible parmi les $nbcons$ disponibles
\item Transformation de cette case en mur (valeur $0$)
\item Mise à jour des 8 voisins : si une case vide devient constructible, elle est ajoutée à la liste ; si une case constructible ne l'est plus, elle est retirée
\item Répétition jusqu'à ce qu'il n'y ait plus de cases constructibles
\end{itemize}
\item Sauvegarde du labyrinthe dans un fichier binaire
\end{enumerate}

\section{Analyse du parallélisme}

\subsection{Identification des dépendances}

L'analyse du code séquentiel révèle que l'algorithme présente des \textbf{dépendances de données} importantes :

\begin{itemize}
\item La sélection aléatoire d'une case constructible dépend du nombre total $nbcons$ de cases constructibles
\item La mise à jour des voisins d'une case construite nécessite l'accès aux 8 cases adjacentes
\item Les cases constructibles peuvent être mises à jour par plusieurs constructions simultanées, créant des conditions de course potentielles
\end{itemize}

Ces dépendances rendent la parallélisation plus complexe que pour des algorithmes à grain fin totalement indépendants. Cependant, il est possible de paralléliser en utilisant une \textbf{décomposition de domaine} : chaque processus gère une portion du labyrinthe et communique avec ses voisins pour synchroniser les frontières.

\subsection{Stratégie de parallélisation}

La stratégie choisie est une \textbf{décomposition de domaine 1D par bandes de lignes} :

\begin{itemize}
\item Le labyrinthe de taille $N \times M$ est divisé en $p$ bandes horizontales de $N/p$ lignes chacune
\item Chaque processus $i$ gère les lignes $[i \cdot N/p, (i+1) \cdot N/p - 1]$
\item Chaque processus maintient deux lignes fantômes (ghost rows) : une au-dessus et une en-dessous de sa bande, pour permettre le calcul correct de la constructibilité des cases frontières
\item Les processus échangent périodiquement leurs lignes frontières pour maintenir la cohérence des données
\end{itemize}

Cette approche présente plusieurs avantages :
\begin{itemize}
\item Réduction de la communication : seules les lignes frontières sont échangées
\item Localité mémoire : chaque processus travaille sur des données contiguës en mémoire
\item Équilibrage de charge : chaque processus traite approximativement le même nombre de lignes
\end{itemize}

\section{Implémentation parallèle}

\subsection{Modifications apportées au code}

Le code parallèle (\texttt{gen\_lab-parallel.c}) introduit plusieurs modifications par rapport à la version séquentielle :

\subsubsection{Initialisation MPI}

\begin{lstlisting}[caption=Initialisation MPI]
MPI_Init(&argc, &argv);
int rank, size;
MPI_Comm_rank(MPI_COMM_WORLD, &rank);
MPI_Comm_size(MPI_COMM_WORLD, &size);
\end{lstlisting}

\subsubsection{Décomposition de domaine}

Chaque processus calcule sa portion locale du labyrinthe :

\begin{lstlisting}[caption=Calcul de la décomposition]
int N_loc = N / size;  // Nombre de lignes locales
int start_row = rank * N_loc;  // Première ligne globale
int local_rows = N_loc + 2;  // +2 pour les lignes fantômes
int(*l)[M] = malloc(sizeof(int[local_rows][M]));
\end{lstlisting}

Les indices locaux $[1, N\_loc]$ correspondent aux lignes réelles, tandis que les indices $0$ et $N\_loc+1$ sont les lignes fantômes.

\subsubsection{Échange de lignes fantômes}

Une fonction dédiée gère l'échange des lignes frontières entre processus voisins :

\begin{lstlisting}[caption=Échange de lignes fantômes]
void update_ghosts(int rows, int cols, int l[rows][cols], 
                   int rank, int size) {
    MPI_Status status;
    int up_neighbor = (rank == 0) ? MPI_PROC_NULL : rank - 1;
    int down_neighbor = (rank == size - 1) ? MPI_PROC_NULL : rank + 1;
    
    // Échange vers le haut
    MPI_Sendrecv(&l[1][0], cols, MPI_INT, up_neighbor, 0,
                 &l[0][0], cols, MPI_INT, up_neighbor, 0,
                 MPI_COMM_WORLD, &status);
    
    // Échange vers le bas
    MPI_Sendrecv(&l[rows-2][0], cols, MPI_INT, down_neighbor, 0,
                 &l[rows-1][0], cols, MPI_INT, down_neighbor, 0,
                 MPI_COMM_WORLD, &status);
}
\end{lstlisting}

L'utilisation de \texttt{MPI\_Sendrecv} garantit l'absence de deadlock et permet un échange efficace des données.

\subsubsection{Boucle principale parallèle}

La boucle principale est modifiée pour gérer la synchronisation entre processus :

\begin{enumerate}
\item Chaque processus calcule son nombre local de cases constructibles $nbcons$
\item Réduction globale avec \texttt{MPI\_Allreduce} pour obtenir le nombre total $global\_nbcons$
\item Si $global\_nbcons = 0$, tous les processus terminent
\item Sinon, chaque processus construit une case si $nbcons > 0$ localement
\item Échange des lignes fantômes pour synchroniser les frontières
\item Re-vérification des cases frontières qui peuvent être devenues constructibles après l'échange
\end{enumerate}

\subsubsection{Reconstitution du labyrinthe}

À la fin du calcul, seul le processus 0 collecte toutes les portions pour reconstituer le labyrinthe complet :

\begin{lstlisting}[caption=Reconstitution avec MPI\_Gather]
int *send_buffer = malloc(N_loc * M * sizeof(int));
// Copie des données locales sans les lignes fantômes
for(int i=0; i<N_loc; i++) {
    memcpy(&send_buffer[i*M], &l[i+1][0], M * sizeof(int));
}

MPI_Gather(send_buffer, N_loc * M, MPI_INT, 
           full_grid, N_loc * M, MPI_INT, 
           0, MPI_COMM_WORLD);
\end{lstlisting}

\subsection{Justification des choix}

\subsubsection{Décomposition 1D vs 2D}

Une décomposition 2D (par blocs) aurait réduit davantage la communication, mais aurait également compliqué l'implémentation. La décomposition 1D par bandes est plus simple à implémenter et suffisante pour des machines avec un nombre modéré de processus.

\subsubsection{Échange périodique des fantômes}

L'échange des lignes fantômes après chaque itération de construction garantit la cohérence des données, mais introduit une surcharge de communication. Une optimisation possible serait d'échanger uniquement lorsque nécessaire, mais cela compliquerait la logique du code.

\subsubsection{Utilisation de MPI\_Allreduce}

L'utilisation de \texttt{MPI\_Allreduce} pour calculer le nombre total de cases constructibles permet à tous les processus de connaître l'état global et de terminer simultanément. Une alternative serait d'utiliser \texttt{MPI\_Reduce} suivi d'un \texttt{MPI\_Bcast}, mais \texttt{MPI\_Allreduce} est plus efficace.

\section{Étude de performances}

\subsection{Environnement d'expérimentation}

Les mesures de performances ont été effectuées sur une machine avec les caractéristiques suivantes :
\begin{itemize}
\item Processeur : Intel Core i5-6300U @ 2.40GHz
\item Nombre de cœurs physiques : 2
\item Nombre de threads logiques : 4 (Hyper-Threading)
\item Compilateur : \texttt{mpicc} avec les options \texttt{-O2 -g -Wall -std=c99}
\item Système d'exploitation : Linux
\end{itemize}

\subsection{Méthodologie}

Pour chaque configuration, j'ai effectué :
\begin{itemize}
\item 3 exécutions du programme
\item Calcul de la moyenne et de l'écart-type des temps d'exécution
\item Mesure du temps total de génération (incluant l'initialisation, le calcul et la sauvegarde)
\end{itemize}

Le nombre de processus est contrôlé via la commande \texttt{mpirun -np}. Pour les configurations avec 3 et 4 processus, j'ai utilisé l'option \texttt{--oversubscribe} pour permettre l'exécution de plus de processus que de cœurs physiques disponibles. Cette option est justifiée car :

\begin{itemize}
\item Elle permet d'étudier le comportement de l'algorithme avec un nombre de processus supérieur au nombre de cœurs physiques
\item Elle simule un environnement où plusieurs processus partagent les mêmes ressources CPU, ce qui est courant dans les clusters HPC
\item Elle permet d'évaluer l'impact de la surcharge de communication et de synchronisation lorsque le nombre de processus augmente
\item Elle est nécessaire pour effectuer une étude complète de scalabilité, même sur une machine avec un nombre limité de cœurs
\end{itemize}

\subsection{Scalabilité forte}

La scalabilité forte mesure l'efficacité de la parallélisation pour une taille de problème fixe. J'ai testé avec les paramètres suivants :
\begin{itemize}
\item Dimensions : $400 \times 600$ pixels
\item Nombre d'îlots : 20
\end{itemize}

Les résultats sont présentés dans le tableau suivant. Les temps sont en secondes, le speedup est calculé comme $S(n) = T_s / T_p(n)$ où $T_s$ est le temps séquentiel et $T_p(n)$ le temps avec $n$ processus. L'efficacité est calculée comme $E(n) = S(n) / n \times 100\%$.

% Les résultats seront insérés ici après les mesures

\begin{table}[H]
\centering
\caption{Résultats de scalabilité forte}
\begin{tabular}{@{}ccccc@{}}
\toprule
Processus & Temps moyen (s) & Écart-type (s) & Speedup & Efficacité (\%) \\
\midrule
1 & 17.84 & 1.08 & 1.00 & 100.0 \\
2 & 5.08 & 0.15 & 3.52 & 175.8 \\
3 & 4.95 & 0.29 & 3.61 & 120.2 \\
4 & 6.64 & 0.43 & 2.69 & 67.2 \\
\bottomrule
\end{tabular}
\end{table}

Le speedup est calculé comme : $S(n) = \frac{T_s}{T_p(n)}$ où $T_s = 17.84$ s est le temps séquentiel et $T_p(n)$ le temps avec $n$ processus.

L'efficacité est calculée comme : $E(n) = \frac{S(n)}{n} \times 100\%$.

Pour mieux comprendre les performances de la parallélisation, comparons les temps d'exécution mesurés avec les temps théoriques optimaux. Le graphique ci-dessous montre l'évolution des temps d'exécution en fonction du nombre de processus, comparant le temps séquentiel $T_s$ (constant), le temps optimal théorique $T_o(n) = T_s/n$ (décroissant linéairement), et le temps parallèle mesuré $T_p(n)$.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    xlabel={Nombre de processus $n$},
    ylabel={Temps d'exécution (s)},
    legend style={at={(0.5,1.03)},anchor=south,legend columns=3},
    grid=major,
    xmin=1, xmax=4,
    ymin=0
]
% Temps séquentiel constant
\addplot[mark=*,blue] coordinates {
    (1,17.84) (2,17.84) (3,17.84) (4,17.84)
};
% Temps optimal théorique
\addplot[mark=*,red,dashed] coordinates {
    (1,17.84) (2,8.92) (3,5.95) (4,4.46)
};
% Temps parallèle mesuré
\addplot[mark=*,green!60!black] coordinates {
    (1,17.84) (2,5.08) (3,4.95) (4,6.64)
};
\legend{$T_s$ (constant), $T_o(n) = T_s/n$ (optimal), $T_p(n)$ (mesuré)}
\end{axis}
\end{tikzpicture}
\caption{Comparaison des temps d'exécution théoriques et mesurés (scalabilité forte)}
\label{fig:temps-execution-forte}
\end{figure}

On observe que le temps parallèle mesuré $T_p(n)$ suit globalement la décroissance du temps optimal $T_o(n)$ pour $n=2$ et $n=3$, avec des performances particulièrement bonnes. Pour $n=4$, on note une dégradation, probablement due à l'oversubscription et à la surcharge de communication.

Passons maintenant à l'analyse de l'accélération obtenue :

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    xlabel={Nombre de processus $n$},
    ylabel={Accélération},
    legend style={at={(0.5,1.03)},anchor=south,legend columns=2},
    grid=major,
    xmin=0.5, xmax=4.5,
    ymin=0,
    ymax=4.5
]
% Accélération mesurée
\addplot[mark=*,blue,thick] coordinates {
    (1,1.00) (2,3.52) (3,3.61) (4,2.69)
};
% Accélération idéale
\addplot[mark=*,red,dashed,thick] coordinates {
    (1,1.00) (2,2.00) (3,3.00) (4,4.00)
};
\legend{Accélération mesurée $S(n)$, Accélération optimale $S_o(n) = n$}
\end{axis}
\end{tikzpicture}
\caption{Scalabilité forte : Accélération en fonction du nombre de processus}
\label{fig:scalabilite-forte}
\end{figure}

\subsection{Scalabilité faible}

La scalabilité faible mesure l'efficacité lorsque la taille du problème augmente proportionnellement au nombre de processus, de manière à maintenir une charge de travail constante par processus. J'ai testé avec les configurations suivantes :

\begin{itemize}
\item 1 processus : $400 \times 600$ pixels (surface de base : 240\,000 pixels)
\item 2 processus : $565 \times 848$ pixels (surface $\times 2$ : 479\,120 pixels)
\item 3 processus : $692 \times 1038$ pixels (surface $\times 3$ : 718\,296 pixels)
\item 4 processus : $800 \times 1200$ pixels (surface $\times 4$ : 960\,000 pixels)
\end{itemize}

Les autres paramètres restent identiques : nombre d'îlots 20.

L'efficacité parallèle est calculée comme : $E(n) = \frac{T_s(1)}{T_p(n)} \times 100\%$ où $T_s(1)$ est le temps séquentiel pour la taille de base et $T_p(n)$ est le temps parallèle pour la taille proportionnelle.

\begin{table}[H]
\centering
\caption{Résultats de scalabilité faible}
\begin{tabular}{@{}cccccc@{}}
\toprule
$n$ & Dimensions & Surface & $T_s(1)$ (s) & $T_p(n)$ (s) & Efficacité (\%) \\
\midrule
1 & $400 \times 600$ & 240\,000 & 16.85 & 16.85 & 100.0 \\
2 & $565 \times 848$ & 479\,120 & 16.85 & 26.15 & 64.4 \\
3 & $692 \times 1038$ & 718\,296 & 16.85 & 47.96 & 35.1 \\
4 & $800 \times 1200$ & 960\,000 & 16.85 & 97.34 & 17.3 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    xlabel={Nombre de processus $n$},
    ylabel={Efficacité parallèle (\%)},
    legend style={at={(0.5,1.03)},anchor=south,legend columns=2},
    grid=minor,
    xmin=0.5, xmax=4.5,
    ymin=0,
    ymax=110
]
% Efficacité mesurée
\addplot[mark=*,blue,thick] coordinates {
    (1,100.0) (2,64.4) (3,35.1) (4,17.3)
};
% Efficacité idéale
\addplot[mark=none,red,dashed,thick] coordinates {
    (1,100) (2,100) (3,100) (4,100)
};
\legend{Efficacité mesurée $E(n)$, Efficacité idéale (100\%)}
\end{axis}
\end{tikzpicture}
\caption{Scalabilité faible : Efficacité parallèle en fonction du nombre de processus}
\label{fig:scalabilite-faible}
\end{figure}

\section{Analyse et discussion}

\subsection{Interprétation des résultats}

\subsubsection{Scalabilité forte}

Les résultats de scalabilité forte montrent un comportement intéressant :

\begin{itemize}
\item \textbf{Avec 1 processus} : Le temps d'exécution est de 17.84 s en moyenne, avec un écart-type de 1.08 s. Cette variabilité s'explique par la nature aléatoire de l'algorithme (sélection aléatoire des cases constructibles).

\item \textbf{Avec 2 processus} : On observe une accélération de 3.52, supérieure à l'accélération idéale de 2.00, avec une efficacité de 175.8\%. Cette performance exceptionnelle peut s'expliquer par plusieurs facteurs :
\begin{itemize}
\item Utilisation optimale des 2 cœurs physiques disponibles
\item Réduction des conflits de cache : chaque processus travaille sur des données distinctes
\item Meilleure utilisation de la mémoire et du cache avec deux processus sur deux cœurs physiques
\item La décomposition de domaine réduit efficacement la charge de travail
\end{itemize}

\item \textbf{Avec 3 processus} : L'accélération atteint 3.61 avec une efficacité de 120.2\%, très proche de l'idéal théorique. Les trois processus se répartissent sur les 2 cœurs physiques (oversubscription), créant un léger déséquilibre mais restant efficace grâce à l'Hyper-Threading. La communication MPI reste limitée avec seulement 3 processus.

\item \textbf{Avec 4 processus} : L'accélération diminue à 2.69 avec une efficacité de 67.2\%, nettement inférieure à l'accélération idéale de 4. Cette dégradation s'explique par :
\begin{itemize}
\item \textbf{Oversubscription} : Le processeur n'a que 2 cœurs physiques. Avec 4 processus, deux threads partagent les mêmes ressources d'un cœur physique, ce qui réduit l'efficacité
\item \textbf{Surcharge de communication} : La communication MPI augmente avec le nombre de processus (échanges de lignes fantômes et synchronisation via \texttt{MPI\_Allreduce})
\item \textbf{Contention mémoire} : Les 4 processus se partagent la même mémoire et le même cache, créant des conflits d'accès
\item \textbf{Synchronisation} : La boucle principale nécessite une synchronisation globale à chaque itération, ce qui devient un goulot d'étranglement avec 4 processus
\end{itemize}

\item \textbf{Efficacité globale} : L'efficacité montre un pic avec 2 processus (175.8\%), se maintient bien avec 3 processus (120.2\%), puis chute significativement avec 4 processus (67.2\%). Cette progression confirme que l'oversubscription ne peut pas compenser l'absence de cœurs physiques supplémentaires au-delà de 2 processus, et que la surcharge de communication devient significative.
\end{itemize}

\subsubsection{Scalabilité faible}

Les résultats de scalabilité faible montrent une efficacité parallèle qui diminue rapidement avec le nombre de processus :

\begin{itemize}
\item \textbf{Avec 1 processus} : L'efficacité est de 100.0\% pour une taille de $400 \times 600$ pixels (surface de 240\,000 pixels). Le temps d'exécution est de 16.85 s en moyenne.

\item \textbf{Avec 2 processus} : L'efficacité chute à 64.4\% pour une taille de $565 \times 848$ pixels (surface $\times 2$ : 479\,120 pixels). Le temps d'exécution passe à 26.15 s, ce qui est supérieur au temps séquentiel de référence. Cette dégradation s'explique par :
\begin{itemize}
\item La surface double, mais le temps ne double pas exactement car la complexité de l'algorithme n'est pas strictement linéaire
\item La communication MPI devient plus importante avec une taille de problème plus grande
\item L'échange des lignes fantômes et la synchronisation via \texttt{MPI\_Allreduce} prennent plus de temps
\end{itemize}

\item \textbf{Avec 3 processus} : L'efficacité chute à 35.1\% pour une taille de $692 \times 1038$ pixels (surface $\times 3$ : 718\,296 pixels). Le temps d'exécution passe à 47.96 s. Cette dégradation importante s'explique par :
\begin{itemize}
\item L'oversubscription : trois processus sur deux cœurs physiques
\item La communication MPI augmente avec le nombre de processus et la taille du problème
\item La synchronisation globale devient un goulot d'étranglement majeur
\end{itemize}

\item \textbf{Avec 4 processus} : L'efficacité chute à 17.3\% pour une taille de $800 \times 1200$ pixels (surface $\times 4$ : 960\,000 pixels). Le temps d'exécution passe à 97.34 s, soit près de 6 fois le temps séquentiel de référence. Cette dégradation sévère s'explique par :
\begin{itemize}
\item L'oversubscription maximale : quatre processus sur deux cœurs physiques
\item La communication MPI devient très coûteuse avec 4 processus et une grande taille de problème
\item La synchronisation globale via \texttt{MPI\_Allreduce} à chaque itération devient un goulot d'étranglement critique
\item La contention mémoire et du cache est maximale
\end{itemize}

\item \textbf{Analyse globale} : La scalabilité faible montre une efficacité qui diminue rapidement avec le nombre de processus, passant de 100\% avec 1 processus à seulement 17.3\% avec 4 processus. Cette dégradation importante indique que l'algorithme ne se prête pas bien à la scalabilité faible sur cette architecture, principalement à cause de la surcharge de communication et de synchronisation qui augmente avec la taille du problème et le nombre de processus.
\end{itemize}

\subsection{Facteurs influençant les performances}

Plusieurs facteurs peuvent influencer les performances de la parallélisation :

\begin{enumerate}
\item \textbf{Surcharge de communication} : échange des lignes fantômes et synchronisation via \texttt{MPI\_Allreduce}
\item \textbf{Équilibrage de charge} : répartition inégale du nombre de cases constructibles entre processus
\item \textbf{Accès mémoire} : localité des données et efficacité du cache
\item \textbf{Architecture du processeur} : nombre de cœurs physiques vs processus logiques (oversubscription)
\item \textbf{Synchronisation} : la boucle principale nécessite une synchronisation globale à chaque itération
\end{enumerate}

\subsection{Améliorations possibles}

Plusieurs optimisations pourraient être envisagées :

\begin{itemize}
\item \textbf{Décomposition 2D} : utiliser une décomposition par blocs pour réduire davantage la communication
\item \textbf{Échange asynchrone} : utiliser \texttt{MPI\_Isend} et \texttt{MPI\_Irecv} pour chevaucher communication et calcul
\item \textbf{Échange conditionnel} : n'échanger les fantômes que lorsque nécessaire (lorsqu'une case frontière a été modifiée)
\item \textbf{Planification dynamique} : répartir dynamiquement les cases constructibles entre processus pour améliorer l'équilibrage de charge
\item \textbf{Optimisation mémoire} : alignement des données pour améliorer les performances du cache
\end{itemize}

\section{Conclusion}

Ce projet a permis de paralléliser avec succès la génération de labyrinthe en utilisant MPI. Les modifications apportées au code séquentiel ont été significatives, introduisant une décomposition de domaine 1D avec échange de lignes fantômes pour maintenir la cohérence des données.

L'implémentation démontre l'efficacité de MPI pour paralléliser des algorithmes avec dépendances de données en utilisant une approche de décomposition de domaine. La génération de labyrinthe se prête bien à ce type de parallélisation grâce à la nature locale des dépendances (chaque case ne dépend que de ses voisins immédiats).

Les résultats de l'étude de performances montrent que la parallélisation est très efficace avec 2 processus (accélération de 3.52, efficacité de 175.8\%), se maintient bien avec 3 processus (accélération de 3.61, efficacité de 120.2\%), mais se dégrade significativement avec 4 processus (accélération de 2.69, efficacité de 67.2\%) en raison de l'oversubscription et de la surcharge de communication. La scalabilité faible présente une efficacité qui diminue rapidement avec le nombre de processus, passant de 100\% avec 1 processus à seulement 17.3\% avec 4 processus, principalement à cause de la surcharge de communication et de synchronisation qui augmente avec la taille du problème.

Cette implémentation démontre que la parallélisation avec MPI peut être très efficace pour des problèmes à grain moyen avec des dépendances locales, mais que la surcharge de communication et de synchronisation peut devenir un goulot d'étranglement lorsque le nombre de processus dépasse le nombre de cœurs physiques disponibles ou lorsque la taille du problème augmente significativement.

\section{Annexes}

\subsection{Code source complet}

Le code source complet est disponible dans les fichiers :
\begin{itemize}
\item \texttt{gen\_lab.c} : version séquentielle de référence
\item \texttt{gen\_lab-parallel.c} : version parallélisée avec MPI
\end{itemize}

\subsection{Commandes de compilation et d'exécution}

\begin{lstlisting}[language=bash, caption=Compilation]
make gen_lab-parallel
\end{lstlisting}

\begin{lstlisting}[language=bash, caption=Exécution avec contrôle du nombre de processus]
\# Version séquentielle
./gen_lab

\# Version parallèle avec 2 processus
mpirun -np 2 ./gen_lab-parallel

\# Version parallèle avec 3 ou 4 processus (oversubscribe)
mpirun -np 3 --oversubscribe ./gen_lab-parallel
mpirun -np 4 --oversubscribe ./gen_lab-parallel
\end{lstlisting}

\begin{thebibliography}{9}
\bibitem{mpi}
Message Passing Interface Forum.
\textit{MPI: A Message-Passing Interface Standard}.
Version 4.0, 2021.

\bibitem{parallel}
Grama, A., Gupta, A., Karypis, G., Kumar, V.
\textit{Introduction to Parallel Computing}.
2nd Edition, Pearson Education, 2003.

\bibitem{domain}
Gropp, W., Lusk, E., Skjellum, A.
\textit{Using MPI: Portable Parallel Programming with the Message-Passing Interface}.
3rd Edition, MIT Press, 2014.
\end{thebibliography}

\end{document}


